# -*- coding: utf-8 -*-
"""Day-56

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t0tmy9yAHNZmmJRkWW-7M52QOAUMXqOe
"""

!pip install boto3
import boto3

def upload_to_s3(bucket_name, file_name, object_name=None):
    """Uploads a file to an S3 bucket."""
    s3 = boto3.client('s3')
    if object_name is None:
        object_name = file_name
    try:
        s3.upload_file(file_name, bucket_name, object_name)
        print(f"File {file_name} uploaded successfully to {bucket_name}/{object_name}")
    except Exception as e:
        print(f"Error uploading file: {e}")

def download_from_s3(bucket_name, object_name, file_name):
    """Downloads a file from an S3 bucket."""
    s3 = boto3.client('s3')
    try:
        s3.download_file(bucket_name, object_name, file_name)
        print(f"File {object_name} downloaded successfully from {bucket_name} to {file_name}")
    except Exception as e:
        print(f"Error downloading file: {e}")

def list_s3_objects(bucket_name):
    """Lists objects in an S3 bucket."""
    s3 = boto3.client('s3')
    try:
        response = s3.list_objects_v2(Bucket=bucket_name)
        if 'Contents' in response:
            for obj in response['Contents']:
                print(obj['Key'])
        else:
            print("Bucket is empty.")
    except Exception as e:
        print(f"Error listing objects: {e}")

BUCKET_NAME = "your-bucket-name"
FILE_TO_UPLOAD = "nlp_dataset.txt"
S3_OBJECT_NAME = "datasets/nlp_dataset.txt"
DOWNLOAD_FILE_NAME = "downloaded_nlp_dataset.txt"
upload_to_s3(BUCKET_NAME, FILE_TO_UPLOAD, S3_OBJECT_NAME)
list_s3_objects(BUCKET_NAME)
download_from_s3(BUCKET_NAME, S3_OBJECT_NAME, DOWNLOAD_FILE_NAME)

